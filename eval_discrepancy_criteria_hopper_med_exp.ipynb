{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8236f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rollout_doc_file_processor\n",
    "import plotter\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d88f44",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dir_path = \"log/hopper-medium-v2/combo/seed_1_timestamp_25-0902-082145_benchmark/rollout_docs\"\n",
    "env_name = \"Hopper-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4dd59b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "doc_paths = [os.path.join(dir_path, f) for f in os.listdir(dir_path) if f.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07023d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "docs = rollout_doc_file_processor.load_rollout_docs(doc_paths, add_model_error_if_not_contained=True, env=env_name, cast_to_nparray=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73e39d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# add epoch info to docs\n",
    "for doc, path in zip(docs, doc_paths):\n",
    "    match = re.search(r'epoch_(\\d+)', path)\n",
    "    if match:\n",
    "        epoch = int(match.group(1))\n",
    "        n = len(doc['obss'])\n",
    "        doc[\"epoch\"] = [epoch] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef0600",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# consolidate all dicts in docs\n",
    "consolidated_doc = {}\n",
    "for doc in docs:\n",
    "    for key, value in doc.items():\n",
    "        if key not in consolidated_doc:\n",
    "            consolidated_doc[key] = []\n",
    "        consolidated_doc[key] += value\n",
    "docs = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd95702",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "consolidated_doc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a3a40",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for k,v in consolidated_doc.items():\n",
    "    consolidated_doc[k] = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dd0a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "    # doc = rollout_doc_file_processor.load_rollout_docs(\"log/hopper-medium-expert-v2/combo/seed_1_timestamp_25-0825-124532/rollout_docs/epoch_220_timesteps_219000_rollout_doc.json\")\n",
    "    # doc = doc[0]\n",
    "    # doc.keys()\n",
    "\n",
    "doc = consolidated_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded0221",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "uncertainty_measures = list(doc.keys())\n",
    "uncertainty_measures.remove('obss')\n",
    "uncertainty_measures.remove('actions')\n",
    "uncertainty_measures.remove('next_obss_predicted')\n",
    "uncertainty_measures.remove('next_obss_real')\n",
    "uncertainty_measures.remove('model_error_l2')\n",
    "uncertainty_measures.remove('rewards_real')\n",
    "uncertainty_measures.remove('epoch')\n",
    "uncertainty_measures.remove('step_nr')\n",
    "\n",
    "uncertainty_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd392e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_correlation_bars(doc, uncertainty_measures, error_key='model_error_l2', title='Correlation of Uncertainty Measures with Model Error', print_corr_values=True, fig_size=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20cabb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Prepare data for correlation matrix\n",
    "uncertainty_data = np.stack([doc[k] for k in uncertainty_measures], axis=1)\n",
    "corr_matrix = np.corrcoef(uncertainty_data, rowvar=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, xticklabels=uncertainty_measures, yticklabels=uncertainty_measures, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Uncertainty Measures\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c85f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_simple_scatter_correlation(doc, x_key, y_key):\n",
    "    x = doc[x_key]\n",
    "    y = doc[y_key]\n",
    "\n",
    "    pearson_corr = np.corrcoef(x, y)[0, 1]\n",
    "    spearman_corr, _ = spearmanr(x, y)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x, y, s=0.5, alpha=0.5)\n",
    "    plt.xlabel(x_key)\n",
    "    plt.ylabel(y_key)\n",
    "    plt.title(f\"Scatter plot: {x_key} vs {y_key}\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Annotate correlations in bottom right\n",
    "    textstr = f\"Pearson r: {pearson_corr:.3f}\\nSpearman r: {spearman_corr:.3f}\"\n",
    "    plt.gca().text(\n",
    "        0.98, 0.02, textstr,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='bottom',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7)\n",
    "    )\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaa1b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for u in uncertainty_measures:\n",
    "    if u != \"dimensionwise_ood_measure\":\n",
    "        plotter.plot_scatter_correlation(\n",
    "            x=doc[u],\n",
    "            y=doc[\"model_error_l2\"],\n",
    "            title=f\"{u} vs Model Error L2\",\n",
    "            xlabel=u,\n",
    "            ylabel=\"Model Error L2\",\n",
    "            bins=256,\n",
    "            mark_percentile=70,\n",
    "            fig_size=(6, 6),\n",
    "            points_s=0.5,\n",
    "            points_alpha=0.05\n",
    "        )\n",
    "    else:\n",
    "        plot_simple_scatter_correlation(doc, u, \"model_error_l2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88125e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_min = -0.6\n",
    "p1 = -0.35\n",
    "\n",
    "p99 = 0.2\n",
    "x_max = 0.35\n",
    "\n",
    "u_max = 5\n",
    "\n",
    "def u(x):\n",
    "    if x < p1:\n",
    "        return ((x - p1)/(x_min - p1))**2\n",
    "    elif x < p99:\n",
    "        return 0\n",
    "    else:\n",
    "        return ((x - p99)/(x_max - p99))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f4dfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# for u in uncertainty_measures:\n",
    "#     if u != \"dimensionwise_ood_measure\":\n",
    "#         plotter.plot_scatter_correlation(\n",
    "#             x=doc[u],\n",
    "#             y=doc[\"rewards_real\"],\n",
    "#             title=f\"{u} vs Rewards Real\",\n",
    "#             xlabel=u,\n",
    "#             ylabel=\"Rewards Real\",\n",
    "#             bins=256,\n",
    "#             mark_percentile=70,\n",
    "#             fig_size=(6, 6),\n",
    "#             points_s=0.5,\n",
    "#             points_alpha=0.05\n",
    "#         )\n",
    "#     else:\n",
    "#         plot_simple_scatter_correlation(doc, u, \"rewards_real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d97196",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "doc.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2582420",
   "metadata": {},
   "source": [
    "#### Fit OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f793d32",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "unc_data = np.stack([doc[k] for k in uncertainty_measures]).T\n",
    "target = doc[\"model_error_l2\"]\n",
    "unc_data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269aa6f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit linear regression model\n",
    "reg_strength = 0.5\n",
    "beta = np.linalg.inv(unc_data.T @ unc_data + reg_strength) @ unc_data.T @ target\n",
    "y_hat = unc_data @ beta\n",
    "beta, y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a127b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_scatter_correlation(x= y_hat, y=doc[\"model_error_l2\"], title=f\"Combining Uncertainty Measures -OLS Error Prediction vs L2 Model Error\", xlabel=\"OLS Error Prediction\", ylabel=\"Model Error L2\", bins=800, mark_percentile=70, fig_size=(6, 6), points_s=0.5, points_alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d99ddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_scatter_correlation(x= y_hat, y=doc[\"rewards_real\"], title=f\"OLS Error Prediction using all uncertainty measures vs Real Reward\", xlabel=\"OLS Error Prediction\", ylabel=\"Real Reward\", bins=800, mark_percentile=70, fig_size=(6, 6), points_s=0.5, points_alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49d34f0",
   "metadata": {},
   "source": [
    "=> No correlation between discrepancy measures and real rewards. Thus, by filtering out data with high discrepancy measure we don't remove well performing transitions in particular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb5274",
   "metadata": {},
   "source": [
    "## Logistic Regression on all Features as Filter Criterion - Target L2 Error Threshold: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e8489",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Logistic Regression to find criterion to filter model_error > 0.1\n",
    "\n",
    "threshold = 0.1\n",
    "\n",
    "targets_log_reg = (doc[\"model_error_l2\"] > threshold).astype(int)\n",
    "sample_weights = np.clip(np.abs(doc[\"model_error_l2\"] - threshold)**0.5, 0, 2) # clipped sqrt abs distance\n",
    "\n",
    "targets_log_reg.shape, sample_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c8b4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(sample_weights, bins=1000, color='skyblue', edgecolor='black')\n",
    "mean_val = np.mean(sample_weights)\n",
    "plt.axvline(mean_val, color='r', linestyle='--', linewidth=1, label=f\"Mean: {mean_val:.3f}\")\n",
    "plt.xlabel(\"Sample Weights\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of Sample Weights for Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc93941",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(unc_data, targets_log_reg, sample_weight=sample_weights)\n",
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5ff40",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_hat_log_reg = log_reg.predict(unc_data)\n",
    "y_hat_log_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c208326",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x = y_hat\n",
    "y = doc[\"model_error_l2\"]\n",
    "\n",
    "# Prepare colors by y_hat_log_reg\n",
    "colors = np.where(y_hat_log_reg == 1, \"red\", \"green\")\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(x, y, c=colors, s=2, alpha=0.1, label=None)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"OLS prediction (log scale)\")\n",
    "plt.ylabel(\"model_error_l2 (log scale)\")\n",
    "plt.title(\"Accepted and Filtered Out Data - Displayed on OLS Prediction vs Model Error Plot\")\n",
    "\n",
    "# Add legend for colors\n",
    "import matplotlib.patches as mpatches\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='green', label='Accepted by Log-Reg'),\n",
    "    mpatches.Patch(color='red', label='Filtered out by Log-Reg')\n",
    "], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3c4bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_hat_log_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a05103",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_filtering_analysis(doc, filter_indicator=y_hat_log_reg, bins=800, fig_size=(22, 9), filter_criterion=\"Logistic Regression Prediction - trained to filter out errors above 0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110e7bf",
   "metadata": {},
   "source": [
    "### Heuristic Filter Criterion - Filter out iff dimensionwise_diff_with_std > 0.15 OR aleatoric > 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9917df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "threshold_dimensionwise = 0.4\n",
    "threshold_aleatoric = 0.35\n",
    "threshold_ood = 2.2\n",
    "filter_indicator = (doc[\"dimensionwise_diff_with_std\"] > threshold_dimensionwise) | (doc[\"aleatoric\"] > threshold_aleatoric ) | (doc[\"dimensionwise_ood_measure\"] > threshold_ood)\n",
    "filter_indicator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c450844d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sum(y_hat_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5e676",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_filtering_analysis(doc, filter_indicator=filter_indicator, bins=600, fig_size=(22, 9), filter_criterion=f\"dimensionwise_diff_with_std > {threshold_dimensionwise} OR aleatoric > {threshold_aleatoric} OR dimensionwise_ood_measure > {threshold_ood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35aa6db",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_model_error_all_vs_accepted_per_step(doc, filter_indicator, epoch_vals=[225,250,350], title='Model Error Analysis With Performant Rollout Policy', statistics=[\"mean\", \"median\", \"P90\"], curves_logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726cb9ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plotter.plot_model_error_all_vs_accepted_per_step(doc, filter_indicator, epoch_vals=[25,50], title='Model Error Analysis With Underfitted Rollout Policy', statistics=[\"mean\", \"median\", \"P90\"], curves_logscale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec39dd90",
   "metadata": {},
   "source": [
    "=> Model error doesn't change much with rollout policy actor quality (with same dynamics model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
